{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ch10_embedding_221101"
      ],
      "metadata": {
        "id": "FW0OIrA_h3D4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 구글 드라이브 연동"
      ],
      "metadata": {
        "id": "uh_YECzHkflb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYLHk-JJh1Bh",
        "outputId": "69de9d48-efb4-4041-ccb2-46da53ad6534"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/산대특/deeplearning/ch10/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVaUZusejQ-w",
        "outputId": "1c3ca806-0e10-45c8-b1e1-e42e013b1dbd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/산대특/deeplearning/ch10/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 패스트텍스트\n",
        "- 패스트텍스트(FastText)는 워드투벡터의 단점을 보완하고자 페이스북에서 개발한 임베딩 알고리즘\n",
        "- 교재 p414 페이지 확인"
      ],
      "metadata": {
        "id": "vC1UT3kBjSXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.ko.vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdEI0IZNjSyg",
        "outputId": "e119ff90-57c3-47f4-98df-ddeaed20f3e4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-01 04:58:23--  https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.ko.vec\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.74.142, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2323010599 (2.2G) [binary/octet-stream]\n",
            "Saving to: ‘wiki.ko.vec’\n",
            "\n",
            "wiki.ko.vec         100%[===================>]   2.16G  37.6MB/s    in 50s     \n",
            "\n",
            "2022-11-01 04:59:14 (44.4 MB/s) - ‘wiki.ko.vec’ saved [2323010599/2323010599]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 글로브\n",
        "- 횟수 기반의 LSA와 예측 기반의 워드투벡터 단점을 보완하기 위한 모델\n",
        "- 교재 p416"
      ],
      "metadata": {
        "id": "FnMrPcqsjUBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18m-LGZajU_g",
        "outputId": "eca6cdc9-22d0-4e7f-e976-6d1bc43d92b2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-01 04:59:14--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-11-01 04:59:14--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  4.98MB/s    in 2m 43s  \n",
            "\n",
            "2022-11-01 05:01:58 (5.03 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pp_j7c64jW4x",
        "outputId": "62fae1d4-b7d7-49ad-b1c4-c25718a32404"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip 'IMDB Dataset.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaszDnNSjXxY",
        "outputId": "883df720-bddc-4dca-c1aa-71037bf06f60"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  IMDB Dataset.zip\n",
            "replace IMDB Dataset.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 원핫 인코딩 적용"
      ],
      "metadata": {
        "id": "5LG5HzookuAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "DATA_PATH = \"/content/drive/MyDrive/Colab Notebooks/산대특/deeplearning/ch10/data/\"\n",
        "\n",
        "class2 = pd.read_csv(DATA_PATH + \"class2.csv\")\n",
        "class2.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CRPQ80yukwcA",
        "outputId": "bcc6c571-446d-4b94-e96a-04a89c33cee5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0      id tissue class class2      x      y      r\n",
              "0           0  CID000      C  CIRC      N  535.0  475.0  192.0\n",
              "1           1  CID001      A  CIRA      N  433.0  268.0   58.0\n",
              "2           2  CID002      A  CIRA      I    NaN    NaN    NaN\n",
              "3           3  CID003      C  CIRC      B    NaN    NaN    NaN\n",
              "4           4  CID004      F  CIRF      I  488.0  145.0   29.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d66212bb-ec5c-40a6-8131-15bb97a2ab90\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>tissue</th>\n",
              "      <th>class</th>\n",
              "      <th>class2</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>r</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>CID000</td>\n",
              "      <td>C</td>\n",
              "      <td>CIRC</td>\n",
              "      <td>N</td>\n",
              "      <td>535.0</td>\n",
              "      <td>475.0</td>\n",
              "      <td>192.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>CID001</td>\n",
              "      <td>A</td>\n",
              "      <td>CIRA</td>\n",
              "      <td>N</td>\n",
              "      <td>433.0</td>\n",
              "      <td>268.0</td>\n",
              "      <td>58.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>CID002</td>\n",
              "      <td>A</td>\n",
              "      <td>CIRA</td>\n",
              "      <td>I</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>CID003</td>\n",
              "      <td>C</td>\n",
              "      <td>CIRC</td>\n",
              "      <td>B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>CID004</td>\n",
              "      <td>F</td>\n",
              "      <td>CIRF</td>\n",
              "      <td>I</td>\n",
              "      <td>488.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>29.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d66212bb-ec5c-40a6-8131-15bb97a2ab90')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d66212bb-ec5c-40a6-8131-15bb97a2ab90 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d66212bb-ec5c-40a6-8131-15bb97a2ab90');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "onehot_encoder = preprocessing.OneHotEncoder()\n",
        "\n",
        "# pd.get_dummies()\n",
        "\n",
        "train_x = label_encoder.fit_transform(class2['class'])\n",
        "train_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98emIY62lG1o",
        "outputId": "cf6a587e-9e1d-4a16-fc1c-53df75b2eaa1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = pd.get_dummies(class2)\n",
        "train_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "_H2qROgplpbW",
        "outputId": "d5d30130-365d-4dcf-c49e-30595944d3cc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0      x      y      r  id_CID000  id_CID001  id_CID002  \\\n",
              "0           0  535.0  475.0  192.0          1          0          0   \n",
              "1           1  433.0  268.0   58.0          0          1          0   \n",
              "2           2    NaN    NaN    NaN          0          0          1   \n",
              "3           3    NaN    NaN    NaN          0          0          0   \n",
              "4           4  488.0  145.0   29.0          0          0          0   \n",
              "5           5  532.0  199.0   21.0          0          0          0   \n",
              "\n",
              "   id_CID003  id_CID004  id_CID005  tissue_A  tissue_C  tissue_F  class_CIRA  \\\n",
              "0          0          0          0         0         1         0           0   \n",
              "1          0          0          0         1         0         0           1   \n",
              "2          0          0          0         1         0         0           1   \n",
              "3          1          0          0         0         1         0           0   \n",
              "4          0          1          0         0         0         1           0   \n",
              "5          0          0          1         0         1         0           0   \n",
              "\n",
              "   class_CIRC  class_CIRF  class2_B  class2_I  class2_N  \n",
              "0           1           0         0         0         1  \n",
              "1           0           0         0         0         1  \n",
              "2           0           0         0         1         0  \n",
              "3           1           0         1         0         0  \n",
              "4           0           1         0         1         0  \n",
              "5           1           0         1         0         0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e429c925-fa83-4a91-b17b-7f7df6581b1e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>r</th>\n",
              "      <th>id_CID000</th>\n",
              "      <th>id_CID001</th>\n",
              "      <th>id_CID002</th>\n",
              "      <th>id_CID003</th>\n",
              "      <th>id_CID004</th>\n",
              "      <th>id_CID005</th>\n",
              "      <th>tissue_A</th>\n",
              "      <th>tissue_C</th>\n",
              "      <th>tissue_F</th>\n",
              "      <th>class_CIRA</th>\n",
              "      <th>class_CIRC</th>\n",
              "      <th>class_CIRF</th>\n",
              "      <th>class2_B</th>\n",
              "      <th>class2_I</th>\n",
              "      <th>class2_N</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>535.0</td>\n",
              "      <td>475.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>433.0</td>\n",
              "      <td>268.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>488.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>532.0</td>\n",
              "      <td>199.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e429c925-fa83-4a91-b17b-7f7df6581b1e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e429c925-fa83-4a91-b17b-7f7df6581b1e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e429c925-fa83-4a91-b17b-7f7df6581b1e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 자연어 처리를 할 때는 원-핫 인코딩 사용 X\n",
        "- 직교를 이룬다 --> 서로 독립적인 관계가 된다.\n",
        "- 대안을 찾자 : 워드투벡터, 글로브, 패스트텍스트 등을 사용한다."
      ],
      "metadata": {
        "id": "j-iQOjSPl-XQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 횟수 기반 임베딩\n",
        "- CountVectorizer, 교재 (p400)"
      ],
      "metadata": {
        "id": "8tsVUQMrmsfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "corpus = [\n",
        "    'This is last chance.',\n",
        "    'and if you do not have this chance.',\n",
        "    'you will never get any chance.',\n",
        "    'will you do get this one?',\n",
        "    'please, get this chance',\n",
        "]\n",
        "vect = CountVectorizer()\n",
        "vect.fit(corpus)\n",
        "vect.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uq2RgAVRmuGQ",
        "outputId": "eb7283f8-5337-49fa-e6c5-bd55d3d79e8d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'this': 13,\n",
              " 'is': 7,\n",
              " 'last': 8,\n",
              " 'chance': 2,\n",
              " 'and': 0,\n",
              " 'if': 6,\n",
              " 'you': 15,\n",
              " 'do': 3,\n",
              " 'not': 10,\n",
              " 'have': 5,\n",
              " 'will': 14,\n",
              " 'never': 9,\n",
              " 'get': 4,\n",
              " 'any': 1,\n",
              " 'one': 11,\n",
              " 'please': 12}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vect.transform([\"you will never get any chance.\"]).toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyNoozzdmyiJ",
        "outputId": "1af23672-be21-4e07-f13b-cf8b2c301277"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vect = CountVectorizer(stop_words=[\"and\", \"is\", \"please\", \"this\"]).fit(corpus)\n",
        "vect.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_P6O16Rm7F3",
        "outputId": "1a01a3fc-ea06-4bbb-8f06-68ab03bb3384"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'last': 6,\n",
              " 'chance': 1,\n",
              " 'if': 5,\n",
              " 'you': 11,\n",
              " 'do': 2,\n",
              " 'not': 8,\n",
              " 'have': 4,\n",
              " 'will': 10,\n",
              " 'never': 7,\n",
              " 'get': 3,\n",
              " 'any': 0,\n",
              " 'one': 9}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- TF-IDF, 교재 (p402)"
      ],
      "metadata": {
        "id": "mFqc-K_3nFvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "doc = ['I like machine learning', 'I love deep learning', 'I run everyday']\n",
        "tfidf_vectorizer = TfidfVectorizer(min_df=1)\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(doc)\n",
        "doc_distance = (tfidf_matrix * tfidf_matrix.T)\n",
        "print ('유사도를 위한', str(doc_distance.get_shape()[0]), 'x', str(doc_distance.get_shape()[1]), '행렬을 만들었습니다.')\n",
        "print(doc_distance.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PG26jyqnXlX",
        "outputId": "a9a03051-8c0d-4e30-d15f-7f669da6bf20"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "유사도를 위한 3 x 3 행렬을 만들었습니다.\n",
            "[[1.       0.224325 0.      ]\n",
            " [0.224325 1.       0.      ]\n",
            " [0.       0.       1.      ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 예측 기반 임베딩\n",
        "- 워드 투 벡터\n",
        "  + 신경망 알고리즘의 하나\n",
        "- and I love this one\n",
        "- one을 입력 --> 출력층 나머지 4개 단어 구성\n",
        "- 각 단어 간의 코사인 유사도를 통해 해당 단어의 의미를 수치화 한다."
      ],
      "metadata": {
        "id": "49qfFG-Unbsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIxYS_B4ngBf",
        "outputId": "1caccb9c-7954-4ac2-eb05-94dcd7839d7a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " class2.csv\t     glove.6B.300d.txt\t'IMDB Dataset.zip'   test.csv\n",
            " example.txt\t     glove.6B.50d.txt\t peter.txt\t     train.csv\n",
            " glove.6B.100d.txt   glove.6B.zip\t spam.csv\t     wiki.ko.vec\n",
            " glove.6B.200d.txt  'IMDB Dataset.csv'\t spa.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1m0IXIlpwUW",
        "outputId": "da7ef96c-ffc1-4f29-a05d-e3a620a748b3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "sample =open(\"peter.txt\", \"r\", encoding=\"UTF-8\")\n",
        "s=sample.read()\n",
        "s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "quZP230Xp7NG",
        "outputId": "3cc54a6b-b5f4-43df-9c0d-68fe8cc60870"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Once upon a time in London, the darlings went out to a dinner party leaving their three children Wendy, Jhon, and Michael at home. After Wendy had tucked her younger brothers Jhon and Michael to bed, she went to read a book. She heard a boy sobbing outside her window. He was flying. There was little fairy fluttering around him. Wendy opened the window to talk to him.\\n\\n“Hello! Who are you? Why are you crying ”, wendy asked him. “My name is Peter Pan. my shadow wouldn’t stock to me.”, He replied. She asked him to come in. Peter agreed and came inside the room. Wendy took his shadow and sewed it to his shoe tips.\\n\\nNow his shadow followed him wherever Peter Pan went! He was delighted and asked Wendy “Why don’t you come with me to my home. The Neverland. I lived there with my fairy Tinker Bell.” Wendy ? “Oh! What a wonderful idea! Let me wake up John and Micheal too. Could you teach us how to fly?”. “Yes! Of course! Get them we will all fly together.” Peter Pan replied\\n\\nAnd so it was. Five little figures flew out of the window of the Darlings and headed towards Neverland. As they flew over the island, Peter pan told the children more about his homeland. “All the children who get lost come and stay with Tinker Bell and me,” Peter told them.\\n\\nThe Indians also live in Neverland. The mermaids live in the lagoon around the island. And a very mean pirate called Captain Hook keeps troubling everyone. “Crocodile bit his one arm. So the captain had to put a hook in its place. Since then he is afraid of crocodiles. And rightly so! If the crocodile ever found Captain Hook it will eat up the rest of it couldn’t eat last time.” Peter told them.\\n\\nSoon they landed on the island. And to the surprise of Wendy, Jhon and Michael, Peter Pan let them in through a small opening in a tree. Inside the tree was a large room with children inside it. Somewhere huddled by the fire in the corner and somewhere playing amongst themselves. Their faces lit up when they saw Peter Pan, Tinker Bell, and their guests.\\n\\n“Hello everyone. This is Wendy, Jhon, and Michael. They will be staying with us from now on.” Peter Pan introduced them to all children. Children welcomed Wendy, Jhon, and Michael.\\n\\nA few days passed. And they settled into a routine. Wendy would take care of all the children in the day and would go out with Peter Pan and her brothers in the evening to learn about the island. She would cook for them and stitch new clothes for them. He even made a lovely new dress for Tinker Bell.\\n\\nOne evening, as they were out exploring the island Peter Pan warned everyone and said, “Hide! Hide! Pirates! and they have kidnapped the Indian princess Tiger Lily. They have kept her there, tied up by the rocks, near the water.”\\n\\nPeter was afraid and the princess would drown, is she fell into the water. So, in a voice that sounded like Captain Hook, he shouted instructions to the pirates who guarded her, “You fools! Let her go at once! Do it before I come there or else I will throw each one of you into the water.”\\n\\nThe pirates got scared and immediately released the princes. She quickly dived into the water and swam to the safety of her home. Soon everyone found out how Peter Pan had rescued the Princess. When Captain Hook found out how Peter had tricked his men he was furious. And swore to have his revenge.\\n\\nThat night Wendy told Peter Pan, that she and her brother wanted to go back home since they missed their parents. She said if the lost children could also return to her world they could find a nice home for them.\\n\\nPeter Pan didn’t want to leave Neverland. But the sake of the lost children he agreed, although a bit sadly. He would miss his friends dearly.\\n\\nThe next morning all the lost children left with Wendy, Jhon, and Michael. But on the way, Captain Hook and his men kidnapped all of them. He tied them and kept them on once of his ships.\\n\\nAs soon as Peter found out about it he rushed to the ship. He swung himself from a tress branch and on to the deck of the ship where all the children were tied up.\\n\\nHe swung his sword bravely and threw over the pirates who tried to stop him. Quickly he released everyone from their captor’s ties. Wendy, Jhon, Michael and Tinker Bell helped all the children into the water, where their friends from the Indian camp were ready with smaller boats to take them to safety\\n\\nPeter Pan now went looking for Captain Hook. “Let us finished this forever Mr. Hook”, Peter challenged Captain Hook. “Yes! Peter Pan, you have caused me enough trouble. It is time that we finished this.”\\n\\nHook replied. With his sword drawn, he raced towards Peter Pan. Quick on his feet, Peter Pan stepped aside and pushed Hook inside the sea where the crocodile was waiting to eat the rest of Hook.\\n\\nEveryone rejoiced as Captain Hook was out of their lives forever. Everybody headed back to London. Mr. and Mrs. Darling was so happy to see their children and they agreed to adopt the lost children.\\n\\nThey even asked Peter Pan to come and live with them. But Peter Pan said, he never wanted to grow up, so he and Tinker Bell will go back to Neverland.\\n\\nPeter Pan promised everyone that he will visit again sometime! And he flew out of the window with Tinker Bell by his side.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 줄바꿈을 공백으로 전환\n",
        "f = s.replace(\"\\n\",\" \")\n",
        "data = []\n",
        "for i in sent_tokenize(f):\n",
        "  temp =[]\n",
        "  for j in word_tokenize(i):\n",
        "    temp.append(j.lower())\n",
        "  data.append(temp)\n",
        "\n",
        "data  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKHqL5HuqKHY",
        "outputId": "02f01b9d-74cc-409c-914b-1f8cf57feacb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['once',\n",
              "  'upon',\n",
              "  'a',\n",
              "  'time',\n",
              "  'in',\n",
              "  'london',\n",
              "  ',',\n",
              "  'the',\n",
              "  'darlings',\n",
              "  'went',\n",
              "  'out',\n",
              "  'to',\n",
              "  'a',\n",
              "  'dinner',\n",
              "  'party',\n",
              "  'leaving',\n",
              "  'their',\n",
              "  'three',\n",
              "  'children',\n",
              "  'wendy',\n",
              "  ',',\n",
              "  'jhon',\n",
              "  ',',\n",
              "  'and',\n",
              "  'michael',\n",
              "  'at',\n",
              "  'home',\n",
              "  '.'],\n",
              " ['after',\n",
              "  'wendy',\n",
              "  'had',\n",
              "  'tucked',\n",
              "  'her',\n",
              "  'younger',\n",
              "  'brothers',\n",
              "  'jhon',\n",
              "  'and',\n",
              "  'michael',\n",
              "  'to',\n",
              "  'bed',\n",
              "  ',',\n",
              "  'she',\n",
              "  'went',\n",
              "  'to',\n",
              "  'read',\n",
              "  'a',\n",
              "  'book',\n",
              "  '.'],\n",
              " ['she', 'heard', 'a', 'boy', 'sobbing', 'outside', 'her', 'window', '.'],\n",
              " ['he', 'was', 'flying', '.'],\n",
              " ['there', 'was', 'little', 'fairy', 'fluttering', 'around', 'him', '.'],\n",
              " ['wendy', 'opened', 'the', 'window', 'to', 'talk', 'to', 'him', '.'],\n",
              " ['“', 'hello', '!'],\n",
              " ['who', 'are', 'you', '?'],\n",
              " ['why', 'are', 'you', 'crying', '”', ',', 'wendy', 'asked', 'him', '.'],\n",
              " ['“', 'my', 'name', 'is', 'peter', 'pan', '.'],\n",
              " ['my',\n",
              "  'shadow',\n",
              "  'wouldn',\n",
              "  '’',\n",
              "  't',\n",
              "  'stock',\n",
              "  'to',\n",
              "  'me.',\n",
              "  '”',\n",
              "  ',',\n",
              "  'he',\n",
              "  'replied',\n",
              "  '.'],\n",
              " ['she', 'asked', 'him', 'to', 'come', 'in', '.'],\n",
              " ['peter', 'agreed', 'and', 'came', 'inside', 'the', 'room', '.'],\n",
              " ['wendy',\n",
              "  'took',\n",
              "  'his',\n",
              "  'shadow',\n",
              "  'and',\n",
              "  'sewed',\n",
              "  'it',\n",
              "  'to',\n",
              "  'his',\n",
              "  'shoe',\n",
              "  'tips',\n",
              "  '.'],\n",
              " ['now',\n",
              "  'his',\n",
              "  'shadow',\n",
              "  'followed',\n",
              "  'him',\n",
              "  'wherever',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'went',\n",
              "  '!'],\n",
              " ['he',\n",
              "  'was',\n",
              "  'delighted',\n",
              "  'and',\n",
              "  'asked',\n",
              "  'wendy',\n",
              "  '“',\n",
              "  'why',\n",
              "  'don',\n",
              "  '’',\n",
              "  't',\n",
              "  'you',\n",
              "  'come',\n",
              "  'with',\n",
              "  'me',\n",
              "  'to',\n",
              "  'my',\n",
              "  'home',\n",
              "  '.'],\n",
              " ['the', 'neverland', '.'],\n",
              " ['i',\n",
              "  'lived',\n",
              "  'there',\n",
              "  'with',\n",
              "  'my',\n",
              "  'fairy',\n",
              "  'tinker',\n",
              "  'bell.',\n",
              "  '”',\n",
              "  'wendy',\n",
              "  '?'],\n",
              " ['“', 'oh', '!'],\n",
              " ['what', 'a', 'wonderful', 'idea', '!'],\n",
              " ['let', 'me', 'wake', 'up', 'john', 'and', 'micheal', 'too', '.'],\n",
              " ['could', 'you', 'teach', 'us', 'how', 'to', 'fly', '?', '”', '.'],\n",
              " ['“', 'yes', '!'],\n",
              " ['of', 'course', '!'],\n",
              " ['get',\n",
              "  'them',\n",
              "  'we',\n",
              "  'will',\n",
              "  'all',\n",
              "  'fly',\n",
              "  'together.',\n",
              "  '”',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'replied',\n",
              "  'and',\n",
              "  'so',\n",
              "  'it',\n",
              "  'was',\n",
              "  '.'],\n",
              " ['five',\n",
              "  'little',\n",
              "  'figures',\n",
              "  'flew',\n",
              "  'out',\n",
              "  'of',\n",
              "  'the',\n",
              "  'window',\n",
              "  'of',\n",
              "  'the',\n",
              "  'darlings',\n",
              "  'and',\n",
              "  'headed',\n",
              "  'towards',\n",
              "  'neverland',\n",
              "  '.'],\n",
              " ['as',\n",
              "  'they',\n",
              "  'flew',\n",
              "  'over',\n",
              "  'the',\n",
              "  'island',\n",
              "  ',',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'told',\n",
              "  'the',\n",
              "  'children',\n",
              "  'more',\n",
              "  'about',\n",
              "  'his',\n",
              "  'homeland',\n",
              "  '.'],\n",
              " ['“',\n",
              "  'all',\n",
              "  'the',\n",
              "  'children',\n",
              "  'who',\n",
              "  'get',\n",
              "  'lost',\n",
              "  'come',\n",
              "  'and',\n",
              "  'stay',\n",
              "  'with',\n",
              "  'tinker',\n",
              "  'bell',\n",
              "  'and',\n",
              "  'me',\n",
              "  ',',\n",
              "  '”',\n",
              "  'peter',\n",
              "  'told',\n",
              "  'them',\n",
              "  '.'],\n",
              " ['the', 'indians', 'also', 'live', 'in', 'neverland', '.'],\n",
              " ['the',\n",
              "  'mermaids',\n",
              "  'live',\n",
              "  'in',\n",
              "  'the',\n",
              "  'lagoon',\n",
              "  'around',\n",
              "  'the',\n",
              "  'island',\n",
              "  '.'],\n",
              " ['and',\n",
              "  'a',\n",
              "  'very',\n",
              "  'mean',\n",
              "  'pirate',\n",
              "  'called',\n",
              "  'captain',\n",
              "  'hook',\n",
              "  'keeps',\n",
              "  'troubling',\n",
              "  'everyone',\n",
              "  '.'],\n",
              " ['“', 'crocodile', 'bit', 'his', 'one', 'arm', '.'],\n",
              " ['so',\n",
              "  'the',\n",
              "  'captain',\n",
              "  'had',\n",
              "  'to',\n",
              "  'put',\n",
              "  'a',\n",
              "  'hook',\n",
              "  'in',\n",
              "  'its',\n",
              "  'place',\n",
              "  '.'],\n",
              " ['since', 'then', 'he', 'is', 'afraid', 'of', 'crocodiles', '.'],\n",
              " ['and', 'rightly', 'so', '!'],\n",
              " ['if',\n",
              "  'the',\n",
              "  'crocodile',\n",
              "  'ever',\n",
              "  'found',\n",
              "  'captain',\n",
              "  'hook',\n",
              "  'it',\n",
              "  'will',\n",
              "  'eat',\n",
              "  'up',\n",
              "  'the',\n",
              "  'rest',\n",
              "  'of',\n",
              "  'it',\n",
              "  'couldn',\n",
              "  '’',\n",
              "  't',\n",
              "  'eat',\n",
              "  'last',\n",
              "  'time.',\n",
              "  '”',\n",
              "  'peter',\n",
              "  'told',\n",
              "  'them',\n",
              "  '.'],\n",
              " ['soon', 'they', 'landed', 'on', 'the', 'island', '.'],\n",
              " ['and',\n",
              "  'to',\n",
              "  'the',\n",
              "  'surprise',\n",
              "  'of',\n",
              "  'wendy',\n",
              "  ',',\n",
              "  'jhon',\n",
              "  'and',\n",
              "  'michael',\n",
              "  ',',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'let',\n",
              "  'them',\n",
              "  'in',\n",
              "  'through',\n",
              "  'a',\n",
              "  'small',\n",
              "  'opening',\n",
              "  'in',\n",
              "  'a',\n",
              "  'tree',\n",
              "  '.'],\n",
              " ['inside',\n",
              "  'the',\n",
              "  'tree',\n",
              "  'was',\n",
              "  'a',\n",
              "  'large',\n",
              "  'room',\n",
              "  'with',\n",
              "  'children',\n",
              "  'inside',\n",
              "  'it',\n",
              "  '.'],\n",
              " ['somewhere',\n",
              "  'huddled',\n",
              "  'by',\n",
              "  'the',\n",
              "  'fire',\n",
              "  'in',\n",
              "  'the',\n",
              "  'corner',\n",
              "  'and',\n",
              "  'somewhere',\n",
              "  'playing',\n",
              "  'amongst',\n",
              "  'themselves',\n",
              "  '.'],\n",
              " ['their',\n",
              "  'faces',\n",
              "  'lit',\n",
              "  'up',\n",
              "  'when',\n",
              "  'they',\n",
              "  'saw',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  ',',\n",
              "  'tinker',\n",
              "  'bell',\n",
              "  ',',\n",
              "  'and',\n",
              "  'their',\n",
              "  'guests',\n",
              "  '.'],\n",
              " ['“', 'hello', 'everyone', '.'],\n",
              " ['this', 'is', 'wendy', ',', 'jhon', ',', 'and', 'michael', '.'],\n",
              " ['they',\n",
              "  'will',\n",
              "  'be',\n",
              "  'staying',\n",
              "  'with',\n",
              "  'us',\n",
              "  'from',\n",
              "  'now',\n",
              "  'on.',\n",
              "  '”',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'introduced',\n",
              "  'them',\n",
              "  'to',\n",
              "  'all',\n",
              "  'children',\n",
              "  '.'],\n",
              " ['children', 'welcomed', 'wendy', ',', 'jhon', ',', 'and', 'michael', '.'],\n",
              " ['a', 'few', 'days', 'passed', '.'],\n",
              " ['and', 'they', 'settled', 'into', 'a', 'routine', '.'],\n",
              " ['wendy',\n",
              "  'would',\n",
              "  'take',\n",
              "  'care',\n",
              "  'of',\n",
              "  'all',\n",
              "  'the',\n",
              "  'children',\n",
              "  'in',\n",
              "  'the',\n",
              "  'day',\n",
              "  'and',\n",
              "  'would',\n",
              "  'go',\n",
              "  'out',\n",
              "  'with',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'and',\n",
              "  'her',\n",
              "  'brothers',\n",
              "  'in',\n",
              "  'the',\n",
              "  'evening',\n",
              "  'to',\n",
              "  'learn',\n",
              "  'about',\n",
              "  'the',\n",
              "  'island',\n",
              "  '.'],\n",
              " ['she',\n",
              "  'would',\n",
              "  'cook',\n",
              "  'for',\n",
              "  'them',\n",
              "  'and',\n",
              "  'stitch',\n",
              "  'new',\n",
              "  'clothes',\n",
              "  'for',\n",
              "  'them',\n",
              "  '.'],\n",
              " ['he',\n",
              "  'even',\n",
              "  'made',\n",
              "  'a',\n",
              "  'lovely',\n",
              "  'new',\n",
              "  'dress',\n",
              "  'for',\n",
              "  'tinker',\n",
              "  'bell',\n",
              "  '.'],\n",
              " ['one',\n",
              "  'evening',\n",
              "  ',',\n",
              "  'as',\n",
              "  'they',\n",
              "  'were',\n",
              "  'out',\n",
              "  'exploring',\n",
              "  'the',\n",
              "  'island',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'warned',\n",
              "  'everyone',\n",
              "  'and',\n",
              "  'said',\n",
              "  ',',\n",
              "  '“',\n",
              "  'hide',\n",
              "  '!'],\n",
              " ['hide', '!'],\n",
              " ['pirates', '!'],\n",
              " ['and',\n",
              "  'they',\n",
              "  'have',\n",
              "  'kidnapped',\n",
              "  'the',\n",
              "  'indian',\n",
              "  'princess',\n",
              "  'tiger',\n",
              "  'lily',\n",
              "  '.'],\n",
              " ['they',\n",
              "  'have',\n",
              "  'kept',\n",
              "  'her',\n",
              "  'there',\n",
              "  ',',\n",
              "  'tied',\n",
              "  'up',\n",
              "  'by',\n",
              "  'the',\n",
              "  'rocks',\n",
              "  ',',\n",
              "  'near',\n",
              "  'the',\n",
              "  'water.',\n",
              "  '”',\n",
              "  'peter',\n",
              "  'was',\n",
              "  'afraid',\n",
              "  'and',\n",
              "  'the',\n",
              "  'princess',\n",
              "  'would',\n",
              "  'drown',\n",
              "  ',',\n",
              "  'is',\n",
              "  'she',\n",
              "  'fell',\n",
              "  'into',\n",
              "  'the',\n",
              "  'water',\n",
              "  '.'],\n",
              " ['so',\n",
              "  ',',\n",
              "  'in',\n",
              "  'a',\n",
              "  'voice',\n",
              "  'that',\n",
              "  'sounded',\n",
              "  'like',\n",
              "  'captain',\n",
              "  'hook',\n",
              "  ',',\n",
              "  'he',\n",
              "  'shouted',\n",
              "  'instructions',\n",
              "  'to',\n",
              "  'the',\n",
              "  'pirates',\n",
              "  'who',\n",
              "  'guarded',\n",
              "  'her',\n",
              "  ',',\n",
              "  '“',\n",
              "  'you',\n",
              "  'fools',\n",
              "  '!'],\n",
              " ['let', 'her', 'go', 'at', 'once', '!'],\n",
              " ['do',\n",
              "  'it',\n",
              "  'before',\n",
              "  'i',\n",
              "  'come',\n",
              "  'there',\n",
              "  'or',\n",
              "  'else',\n",
              "  'i',\n",
              "  'will',\n",
              "  'throw',\n",
              "  'each',\n",
              "  'one',\n",
              "  'of',\n",
              "  'you',\n",
              "  'into',\n",
              "  'the',\n",
              "  'water.',\n",
              "  '”',\n",
              "  'the',\n",
              "  'pirates',\n",
              "  'got',\n",
              "  'scared',\n",
              "  'and',\n",
              "  'immediately',\n",
              "  'released',\n",
              "  'the',\n",
              "  'princes',\n",
              "  '.'],\n",
              " ['she',\n",
              "  'quickly',\n",
              "  'dived',\n",
              "  'into',\n",
              "  'the',\n",
              "  'water',\n",
              "  'and',\n",
              "  'swam',\n",
              "  'to',\n",
              "  'the',\n",
              "  'safety',\n",
              "  'of',\n",
              "  'her',\n",
              "  'home',\n",
              "  '.'],\n",
              " ['soon',\n",
              "  'everyone',\n",
              "  'found',\n",
              "  'out',\n",
              "  'how',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'had',\n",
              "  'rescued',\n",
              "  'the',\n",
              "  'princess',\n",
              "  '.'],\n",
              " ['when',\n",
              "  'captain',\n",
              "  'hook',\n",
              "  'found',\n",
              "  'out',\n",
              "  'how',\n",
              "  'peter',\n",
              "  'had',\n",
              "  'tricked',\n",
              "  'his',\n",
              "  'men',\n",
              "  'he',\n",
              "  'was',\n",
              "  'furious',\n",
              "  '.'],\n",
              " ['and', 'swore', 'to', 'have', 'his', 'revenge', '.'],\n",
              " ['that',\n",
              "  'night',\n",
              "  'wendy',\n",
              "  'told',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  ',',\n",
              "  'that',\n",
              "  'she',\n",
              "  'and',\n",
              "  'her',\n",
              "  'brother',\n",
              "  'wanted',\n",
              "  'to',\n",
              "  'go',\n",
              "  'back',\n",
              "  'home',\n",
              "  'since',\n",
              "  'they',\n",
              "  'missed',\n",
              "  'their',\n",
              "  'parents',\n",
              "  '.'],\n",
              " ['she',\n",
              "  'said',\n",
              "  'if',\n",
              "  'the',\n",
              "  'lost',\n",
              "  'children',\n",
              "  'could',\n",
              "  'also',\n",
              "  'return',\n",
              "  'to',\n",
              "  'her',\n",
              "  'world',\n",
              "  'they',\n",
              "  'could',\n",
              "  'find',\n",
              "  'a',\n",
              "  'nice',\n",
              "  'home',\n",
              "  'for',\n",
              "  'them',\n",
              "  '.'],\n",
              " ['peter', 'pan', 'didn', '’', 't', 'want', 'to', 'leave', 'neverland', '.'],\n",
              " ['but',\n",
              "  'the',\n",
              "  'sake',\n",
              "  'of',\n",
              "  'the',\n",
              "  'lost',\n",
              "  'children',\n",
              "  'he',\n",
              "  'agreed',\n",
              "  ',',\n",
              "  'although',\n",
              "  'a',\n",
              "  'bit',\n",
              "  'sadly',\n",
              "  '.'],\n",
              " ['he', 'would', 'miss', 'his', 'friends', 'dearly', '.'],\n",
              " ['the',\n",
              "  'next',\n",
              "  'morning',\n",
              "  'all',\n",
              "  'the',\n",
              "  'lost',\n",
              "  'children',\n",
              "  'left',\n",
              "  'with',\n",
              "  'wendy',\n",
              "  ',',\n",
              "  'jhon',\n",
              "  ',',\n",
              "  'and',\n",
              "  'michael',\n",
              "  '.'],\n",
              " ['but',\n",
              "  'on',\n",
              "  'the',\n",
              "  'way',\n",
              "  ',',\n",
              "  'captain',\n",
              "  'hook',\n",
              "  'and',\n",
              "  'his',\n",
              "  'men',\n",
              "  'kidnapped',\n",
              "  'all',\n",
              "  'of',\n",
              "  'them',\n",
              "  '.'],\n",
              " ['he',\n",
              "  'tied',\n",
              "  'them',\n",
              "  'and',\n",
              "  'kept',\n",
              "  'them',\n",
              "  'on',\n",
              "  'once',\n",
              "  'of',\n",
              "  'his',\n",
              "  'ships',\n",
              "  '.'],\n",
              " ['as',\n",
              "  'soon',\n",
              "  'as',\n",
              "  'peter',\n",
              "  'found',\n",
              "  'out',\n",
              "  'about',\n",
              "  'it',\n",
              "  'he',\n",
              "  'rushed',\n",
              "  'to',\n",
              "  'the',\n",
              "  'ship',\n",
              "  '.'],\n",
              " ['he',\n",
              "  'swung',\n",
              "  'himself',\n",
              "  'from',\n",
              "  'a',\n",
              "  'tress',\n",
              "  'branch',\n",
              "  'and',\n",
              "  'on',\n",
              "  'to',\n",
              "  'the',\n",
              "  'deck',\n",
              "  'of',\n",
              "  'the',\n",
              "  'ship',\n",
              "  'where',\n",
              "  'all',\n",
              "  'the',\n",
              "  'children',\n",
              "  'were',\n",
              "  'tied',\n",
              "  'up',\n",
              "  '.'],\n",
              " ['he',\n",
              "  'swung',\n",
              "  'his',\n",
              "  'sword',\n",
              "  'bravely',\n",
              "  'and',\n",
              "  'threw',\n",
              "  'over',\n",
              "  'the',\n",
              "  'pirates',\n",
              "  'who',\n",
              "  'tried',\n",
              "  'to',\n",
              "  'stop',\n",
              "  'him',\n",
              "  '.'],\n",
              " ['quickly',\n",
              "  'he',\n",
              "  'released',\n",
              "  'everyone',\n",
              "  'from',\n",
              "  'their',\n",
              "  'captor',\n",
              "  '’',\n",
              "  's',\n",
              "  'ties',\n",
              "  '.'],\n",
              " ['wendy',\n",
              "  ',',\n",
              "  'jhon',\n",
              "  ',',\n",
              "  'michael',\n",
              "  'and',\n",
              "  'tinker',\n",
              "  'bell',\n",
              "  'helped',\n",
              "  'all',\n",
              "  'the',\n",
              "  'children',\n",
              "  'into',\n",
              "  'the',\n",
              "  'water',\n",
              "  ',',\n",
              "  'where',\n",
              "  'their',\n",
              "  'friends',\n",
              "  'from',\n",
              "  'the',\n",
              "  'indian',\n",
              "  'camp',\n",
              "  'were',\n",
              "  'ready',\n",
              "  'with',\n",
              "  'smaller',\n",
              "  'boats',\n",
              "  'to',\n",
              "  'take',\n",
              "  'them',\n",
              "  'to',\n",
              "  'safety',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'now',\n",
              "  'went',\n",
              "  'looking',\n",
              "  'for',\n",
              "  'captain',\n",
              "  'hook',\n",
              "  '.'],\n",
              " ['“',\n",
              "  'let',\n",
              "  'us',\n",
              "  'finished',\n",
              "  'this',\n",
              "  'forever',\n",
              "  'mr.',\n",
              "  'hook',\n",
              "  '”',\n",
              "  ',',\n",
              "  'peter',\n",
              "  'challenged',\n",
              "  'captain',\n",
              "  'hook',\n",
              "  '.'],\n",
              " ['“', 'yes', '!'],\n",
              " ['peter',\n",
              "  'pan',\n",
              "  ',',\n",
              "  'you',\n",
              "  'have',\n",
              "  'caused',\n",
              "  'me',\n",
              "  'enough',\n",
              "  'trouble',\n",
              "  '.'],\n",
              " ['it',\n",
              "  'is',\n",
              "  'time',\n",
              "  'that',\n",
              "  'we',\n",
              "  'finished',\n",
              "  'this.',\n",
              "  '”',\n",
              "  'hook',\n",
              "  'replied',\n",
              "  '.'],\n",
              " ['with',\n",
              "  'his',\n",
              "  'sword',\n",
              "  'drawn',\n",
              "  ',',\n",
              "  'he',\n",
              "  'raced',\n",
              "  'towards',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  '.'],\n",
              " ['quick',\n",
              "  'on',\n",
              "  'his',\n",
              "  'feet',\n",
              "  ',',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'stepped',\n",
              "  'aside',\n",
              "  'and',\n",
              "  'pushed',\n",
              "  'hook',\n",
              "  'inside',\n",
              "  'the',\n",
              "  'sea',\n",
              "  'where',\n",
              "  'the',\n",
              "  'crocodile',\n",
              "  'was',\n",
              "  'waiting',\n",
              "  'to',\n",
              "  'eat',\n",
              "  'the',\n",
              "  'rest',\n",
              "  'of',\n",
              "  'hook',\n",
              "  '.'],\n",
              " ['everyone',\n",
              "  'rejoiced',\n",
              "  'as',\n",
              "  'captain',\n",
              "  'hook',\n",
              "  'was',\n",
              "  'out',\n",
              "  'of',\n",
              "  'their',\n",
              "  'lives',\n",
              "  'forever',\n",
              "  '.'],\n",
              " ['everybody', 'headed', 'back', 'to', 'london', '.'],\n",
              " ['mr.', 'and', 'mrs', '.'],\n",
              " ['darling',\n",
              "  'was',\n",
              "  'so',\n",
              "  'happy',\n",
              "  'to',\n",
              "  'see',\n",
              "  'their',\n",
              "  'children',\n",
              "  'and',\n",
              "  'they',\n",
              "  'agreed',\n",
              "  'to',\n",
              "  'adopt',\n",
              "  'the',\n",
              "  'lost',\n",
              "  'children',\n",
              "  '.'],\n",
              " ['they',\n",
              "  'even',\n",
              "  'asked',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'to',\n",
              "  'come',\n",
              "  'and',\n",
              "  'live',\n",
              "  'with',\n",
              "  'them',\n",
              "  '.'],\n",
              " ['but',\n",
              "  'peter',\n",
              "  'pan',\n",
              "  'said',\n",
              "  ',',\n",
              "  'he',\n",
              "  'never',\n",
              "  'wanted',\n",
              "  'to',\n",
              "  'grow',\n",
              "  'up',\n",
              "  ',',\n",
              "  'so',\n",
              "  'he',\n",
              "  'and',\n",
              "  'tinker',\n",
              "  'bell',\n",
              "  'will',\n",
              "  'go',\n",
              "  'back',\n",
              "  'to',\n",
              "  'neverland',\n",
              "  '.'],\n",
              " ['peter',\n",
              "  'pan',\n",
              "  'promised',\n",
              "  'everyone',\n",
              "  'that',\n",
              "  'he',\n",
              "  'will',\n",
              "  'visit',\n",
              "  'again',\n",
              "  'sometime',\n",
              "  '!'],\n",
              " ['and',\n",
              "  'he',\n",
              "  'flew',\n",
              "  'out',\n",
              "  'of',\n",
              "  'the',\n",
              "  'window',\n",
              "  'with',\n",
              "  'tinker',\n",
              "  'bell',\n",
              "  'by',\n",
              "  'his',\n",
              "  'side',\n",
              "  '.']]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 단어간 유사성을 확인"
      ],
      "metadata": {
        "id": "455nczWzq34A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sg=0, CBOW 알고리즘 선택\n",
        "# sg=1, skip-gram 알고리즘을 선택한다.\n",
        "model1 = gensim.models.Word2Vec(data, min_count=1,\n",
        "                               size=100,window=5,sg=0)\n",
        "\n",
        "print(\"Cosine similarity between 'peter' \" +\n",
        "                 \"'hook' - CBOW : \", \n",
        "      model1.similarity('peter', 'hook')) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUR4IR1wq5im",
        "outputId": "017dca8f-0e24-4bf6-aeae-783e4dc46630"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity between 'peter' 'hook' - CBOW :  0.083885044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Cosine similarity between 'peter' \" +\n",
        "                 \"'wendy' - CBOW : \", \n",
        "      model1.similarity('peter', 'wendy')) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgOAyA0hsXJt",
        "outputId": "b2f6fba0-43ab-45d4-9390-08c6b255fb42"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity between 'peter' 'wendy' - CBOW :  0.10191567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sg=0, CBOW 알고리즘 선택\n",
        "# sg=1, skip-gram 알고리즘을 선택한다.\n",
        "model2 = gensim.models.Word2Vec(data, min_count=1,\n",
        "                               size=100,window=5,sg=1)\n",
        "\n",
        "print(\"Cosine similarity between 'peter' \" +\n",
        "                 \"'hook' - Skip Gram : \", \n",
        "      model2.similarity('peter', 'hook')) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Pa0BZqJsMTX",
        "outputId": "288f717e-4a4e-4e4c-f0bb-aca29475d5bc"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity between 'peter' 'hook' - Skip Gram :  0.55354315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Cosine similarity between 'peter' \" +\n",
        "                 \"'wendy' - Skip Gram : \", \n",
        "      model2.similarity('peter', 'wendy')) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZ63mjdOsay2",
        "outputId": "5b172c46-b861-449e-8126-339dff0d7d21"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity between 'peter' 'wendy' - Skip Gram :  0.37650046\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 패스트텍스트\n",
        "- 워드 투 벡터 : 사전에 모르는 단어는 학습이 어려움\n",
        "- 워드 투 벡터의 단점을 보완함.\n",
        "- 소파 위에 있는 고양이가 낮잠을 잔다.\n",
        "  + 워드 투 벡터 --> 문장 1개만 사용\n",
        "  + N-그램 --> 세트를 3개 정도"
      ],
      "metadata": {
        "id": "nMYDaLm7wcCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.test.utils import common_texts \n",
        "from gensim.models import FastText \n",
        "\n",
        "corpus_fname = 'peter.txt'\n",
        "corpus = [sent.strip().split(\" \") for sent in open(corpus_fname, 'r', encoding='utf-8').readlines()]\n",
        "model = FastText(corpus, size=4, window=3, min_count = 1, iter = 10)\n",
        "\n",
        "sim_score = model.wv.similarity('peter', 'wendy')\n",
        "print(sim_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_HwebIzxaPO",
        "outputId": "e7f6b8d0-975c-49f7-e785-02206ab313e2"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.5548141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sim_score = model.wv.similarity('peter', 'hook')\n",
        "print(sim_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q87nE96iynSc",
        "outputId": "3391d3e1-bbda-4956-87fe-cf17ef325bd3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.1171107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 한글 모델 사용\n",
        "- 사전 훈련된 모델을 호출하자."
      ],
      "metadata": {
        "id": "l_sh56iPyvZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4k9pvBqYyrqg",
        "outputId": "5af077f6-3e3b-450a-f85d-4bc470c9391d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " class2.csv\t     glove.6B.300d.txt\t'IMDB Dataset.zip'   test.csv\n",
            " example.txt\t     glove.6B.50d.txt\t peter.txt\t     train.csv\n",
            " glove.6B.100d.txt   glove.6B.zip\t spam.csv\t     wiki.ko.vec\n",
            " glove.6B.200d.txt  'IMDB Dataset.csv'\t spa.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "model_kr = KeyedVectors.load_word2vec_format(\"wiki.ko.vec\")\n",
        "print(model_kr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djPqTcOCy0sE",
        "outputId": "abae487c-8638-4bd1-d44d-c88fae6d143b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<gensim.models.keyedvectors.Word2VecKeyedVectors object at 0x7efe4c9cf3d0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "find_similar_to = '노력'\n",
        "\n",
        "for similar_word in model_kr.similar_by_word(find_similar_to):\n",
        "    print(\"Word: {0}, Similarity: {1:.2f}\".format(\n",
        "        similar_word[0], similar_word[1]\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGuaM0t3ztm_",
        "outputId": "f8c4d3d0-7f38-4713-f9ce-f8aa251d5092"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: 노력함, Similarity: 0.80\n",
            "Word: 노력중, Similarity: 0.75\n",
            "Word: 노력만, Similarity: 0.72\n",
            "Word: 노력과, Similarity: 0.71\n",
            "Word: 노력의, Similarity: 0.69\n",
            "Word: 노력가, Similarity: 0.69\n",
            "Word: 노력이나, Similarity: 0.69\n",
            "Word: 노력없이, Similarity: 0.68\n",
            "Word: 노력맨, Similarity: 0.68\n",
            "Word: 노력보다는, Similarity: 0.68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarities = model_kr.wv.most_similar(positive=['동물', '육식동물'], negative=['사람'])\n",
        "print(similarities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0F_pFSFO0A2N",
        "outputId": "d165fe07-b55e-40f6-bc89-f49ff9f87a82"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('초식동물', 0.7804122567176819), ('거대동물', 0.7547270059585571), ('육식동물의', 0.7547166347503662), ('유두동물', 0.7535113096237183), ('반추동물', 0.7470757961273193), ('독동물', 0.7466292381286621), ('육상동물', 0.746031641960144), ('유즐동물', 0.7450904846191406), ('극피동물', 0.7449344992637634), ('복모동물', 0.7424346208572388)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarities = model_kr.wv.most_similar(positive=['일본', '중국'], negative=['한국'])\n",
        "print(similarities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhEYr7UH0oG0",
        "outputId": "caa4d627-9d65-4154-a576-fc4f62d22fac"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('중화인민공하국', 0.6181370615959167), ('중화인민공화국', 0.5936577320098877), ('톈랴오', 0.586189329624176), ('톈중', 0.5725148916244507), ('대만', 0.5692499876022339), ('톈진의', 0.569195032119751), ('훙후', 0.5680252313613892), ('중국등', 0.5665101408958435), ('광저우시', 0.5654244422912598), ('랴오중카이', 0.5621193647384644)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 횟수/예측 기반 임베딩\n",
        "- 횟수 기반 임베딩의 단점\n",
        "- 예측 기반 임베딩의 단점\n",
        "- Glove : 위 두개의 알고리즘 단점을 보완."
      ],
      "metadata": {
        "id": "aEnOlicH1BJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qM3oYrs31qR0",
        "outputId": "76cccce0-1f44-4012-8b31-a38502d4b69f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " class2.csv\t     glove.6B.300d.txt\t'IMDB Dataset.zip'   test.csv\n",
            " example.txt\t     glove.6B.50d.txt\t peter.txt\t     train.csv\n",
            " glove.6B.100d.txt   glove.6B.zip\t spam.csv\t     wiki.ko.vec\n",
            " glove.6B.200d.txt  'IMDB Dataset.csv'\t spa.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "%matplotlib notebook\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "from sklearn.decomposition import PCA\n",
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "\n",
        "glove_file = 'glove.6B.100d.txt'\n",
        "word2vec_glove_file = get_tmpfile ('glove.6B.100d.word2vec.txt')\n",
        "glove2word2vec(glove_file, word2vec_glove_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_4zfciz1kCV",
        "outputId": "bc33655c-7799-4c0a-df45-58e018684ef3"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400000, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = KeyedVectors.load_word2vec_format(word2vec_glove_file)\n",
        "model.most_similar('bill')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23p4yIhi2wiL",
        "outputId": "4b9c5481-7b83-468a-a505-b76aca212470"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('legislation', 0.8072140216827393),\n",
              " ('proposal', 0.7306863069534302),\n",
              " ('senate', 0.7142540812492371),\n",
              " ('bills', 0.7044401168823242),\n",
              " ('measure', 0.6958035230636597),\n",
              " ('passed', 0.6906244158744812),\n",
              " ('amendment', 0.6846879720687866),\n",
              " ('provision', 0.6845567226409912),\n",
              " ('plan', 0.6816462874412537),\n",
              " ('clinton', 0.6663139462471008)]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## p.419 트랜스포머 어텐션\n",
        "- 자연어 알고리즘의 가장 중요한 핵심!\n",
        "- 지금 현재\n",
        "  + 트랜스포머 알고리즘 시대!\n",
        "- 단어 번역\n",
        "  + 새로운 단어, 다른 모든 단어와 비교해서 번역\n",
        "  + 병렬구조로 처리 --> 속도도 향상 / 정확도도 향상\n",
        "- 영향력\n",
        "  + GPT-123 계열 \n",
        "  + Bert 계열"
      ],
      "metadata": {
        "id": "yMwZ064C24oV"
      }
    }
  ]
}